import { useState } from 'react';
import { useTranslation } from 'react-i18next';
import axios from 'axios';
import { Demo, ParameterSlider, Button, Chart, AlgorithmHeader, PlayIcon, ResetIcon } from '@common/modules/MDX/MDXComponents';
import { useLogger } from '@common/modules/Logger';
import { useExceptions, ExceptionType, ExceptionSeverity } from '@common/modules/Exceptions';

export const KMeansDemo = () => {
  const { t } = useTranslation();
  const logger = useLogger();
  const { captureException } = useExceptions();
  const [nClusters, setNClusters] = useState(3);
  const [maxIter, setMaxIter] = useState(300);
  const [loading, setLoading] = useState(false);
  const [result, setResult] = useState(null);

  const runTraining = async () => {
    setLoading(true);
    logger.info('å¼€å§‹ K-Means èšç±»', { nClusters, maxIter });
    
    try {
      const response = await axios.post('/api/algorithms/unsupervised/kmeans/train', {
        n_clusters: nClusters,
        max_iter: maxIter,
      });
      setResult(response.data);
      logger.info('K-Means èšç±»æˆåŠŸ', { result: response.data });
    } catch (error) {
      logger.error('K-Means èšç±»å¤±è´¥', { error: error.message, nClusters, maxIter });
      captureException(error, {
        type: ExceptionType.NETWORK,
        severity: ExceptionSeverity.HIGH,
        context: { 
          algorithm: 'kmeans',
          nClusters,
          maxIter,
          message: 'èšç±»å¤±è´¥ï¼Œè¯·æ£€æŸ¥åç«¯æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ'
        }
      });
    } finally {
      setLoading(false);
    }
  };

  const resetParameters = () => {
    setNClusters(3);
    setMaxIter(300);
    setResult(null);
  };

  return (
    <Demo title="âš¡ äº¤äº’å¼å®éªŒ">
      <div className="space-y-6">
        <div className="bg-gray-50 dark:bg-gray-800 p-4 rounded-lg">
          <h4 className="font-semibold mb-4 text-gray-900 dark:text-gray-100">ğŸ“Š å‚æ•°è°ƒæ•´</h4>
          
          <ParameterSlider
            label="èšç±»æ•°é‡ (K)"
            value={nClusters}
            onChange={setNClusters}
            min={2}
            max={10}
            step={1}
          />
          
          <ParameterSlider
            label="æœ€å¤§è¿­ä»£æ¬¡æ•° (Max Iterations)"
            value={maxIter}
            onChange={setMaxIter}
            min={10}
            max={1000}
            step={10}
          />

          <div className="flex gap-3 mt-6">
            <Button onClick={runTraining} icon={PlayIcon} disabled={loading}>
              {loading ? 'èšç±»ä¸­...' : 'è¿è¡Œèšç±»'}
            </Button>
            <Button onClick={resetParameters} variant="secondary" icon={ResetIcon}>
              é‡ç½®å‚æ•°
            </Button>
          </div>
        </div>

        {result && (
          <div className="space-y-4">
            <div className="bg-purple-50 dark:bg-purple-900/20 p-4 rounded-lg">
              <h4 className="font-semibold mb-2 text-gray-900 dark:text-gray-100">ğŸ¯ èšç±»ç»“æœ</h4>
              <div className="grid grid-cols-2 gap-4 text-sm">
                <div>
                  <span className="text-gray-600 dark:text-gray-400">è½®å»“ç³»æ•° (Silhouette Score):</span>
                  <span className="ml-2 font-mono font-semibold">{result.silhouette_score?.toFixed(4)}</span>
                </div>
                <div>
                  <span className="text-gray-600 dark:text-gray-400">è¿­ä»£æ¬¡æ•°:</span>
                  <span className="ml-2 font-mono font-semibold">{result.n_iter}</span>
                </div>
                <div>
                  <span className="text-gray-600 dark:text-gray-400">æƒ¯æ€§ (Inertia):</span>
                  <span className="ml-2 font-mono font-semibold">{result.inertia?.toFixed(2)}</span>
                </div>
                <div>
                  <span className="text-gray-600 dark:text-gray-400">èšç±»æ•°:</span>
                  <span className="ml-2 font-mono font-semibold">{result.n_clusters}</span>
                </div>
              </div>
            </div>

            {result.plot_data && (
              <Chart
                data={result.plot_data}
                layout={{
                  title: 'K-Means èšç±»ç»“æœ',
                  xaxis: { title: 'Feature 1' },
                  yaxis: { title: 'Feature 2' },
                  height: 400,
                }}
              />
            )}
          </div>
        )}
      </div>
    </Demo>
  );
};

<AlgorithmHeader 
  title="Kå‡å€¼èšç±» K-Means Clustering"
  difficulty="beginner"
  stars={2}
  time={20}
/>

## 1ï¸âƒ£ ç®—æ³•æ¦‚è§ˆ

**K-Means**ï¼ˆKå‡å€¼èšç±»ï¼‰æ˜¯æœ€ç»å…¸ã€æœ€å¸¸ç”¨çš„**æ— ç›‘ç£å­¦ä¹ **ç®—æ³•ä¹‹ä¸€ï¼Œç”¨äºå°†æ•°æ®é›†åˆ’åˆ†ä¸º $K$ ä¸ªç°‡ï¼ˆclusterï¼‰ã€‚ç®—æ³•é€šè¿‡è¿­ä»£ä¼˜åŒ–ï¼Œä½¿å¾—æ¯ä¸ªç°‡å†…çš„æ ·æœ¬å°½å¯èƒ½ç›¸ä¼¼ï¼Œä¸åŒç°‡ä¹‹é—´çš„æ ·æœ¬å°½å¯èƒ½ä¸åŒã€‚

### æ ¸å¿ƒæ€æƒ³

- éšæœºåˆå§‹åŒ– $K$ ä¸ª**èšç±»ä¸­å¿ƒ**ï¼ˆcentroidsï¼‰
- å°†æ¯ä¸ªæ ·æœ¬åˆ†é…åˆ°æœ€è¿‘çš„èšç±»ä¸­å¿ƒ
- é‡æ–°è®¡ç®—æ¯ä¸ªç°‡çš„ä¸­å¿ƒï¼ˆç°‡å†…æ‰€æœ‰æ ·æœ¬çš„å‡å€¼ï¼‰
- é‡å¤ä¸Šè¿°æ­¥éª¤ç›´åˆ°æ”¶æ•›ï¼ˆä¸­å¿ƒä¸å†å˜åŒ–ï¼‰

### åº”ç”¨åœºæ™¯

- ğŸ›ï¸ **å®¢æˆ·ç»†åˆ†**ï¼šæ ¹æ®è´­ä¹°è¡Œä¸ºå°†å®¢æˆ·åˆ†ç»„
- ğŸ–¼ï¸ **å›¾åƒå‹ç¼©**ï¼šå°†ç›¸ä¼¼é¢œè‰²èšä¸ºä¸€ç±»ï¼Œå‡å°‘é¢œè‰²æ•°é‡
- ğŸ“Š **å¸‚åœºåˆ†æ**ï¼šè¯†åˆ«ä¸åŒçš„å¸‚åœºç»†åˆ†
- ğŸ” **å¼‚å¸¸æ£€æµ‹**ï¼šè¿œç¦»æ‰€æœ‰èšç±»ä¸­å¿ƒçš„æ ·æœ¬å¯èƒ½æ˜¯å¼‚å¸¸å€¼

---

## 2ï¸âƒ£ å‘å±•å†å²

- **1957å¹´** - **Stuart Lloyd** åœ¨è´å°”å®éªŒå®¤æå‡º K-Means ç®—æ³•ï¼ˆä½†ç›´åˆ° 1982 å¹´æ‰å‘è¡¨ï¼‰
- **1965å¹´** - **E. W. Forgy** ç‹¬ç«‹å‘ç°å¹¶å‘è¡¨äº†ç±»ä¼¼ç®—æ³•
- **1967å¹´** - **James MacQueen** æ­£å¼ä½¿ç”¨ "K-Means" è¿™ä¸ªæœ¯è¯­
- **1982å¹´** - Lloyd çš„åŸå§‹è®ºæ–‡æ­£å¼å‘è¡¨
- **21ä¸–çºª** - K-Means æˆä¸ºæ•°æ®æŒ–æ˜å’Œæœºå™¨å­¦ä¹ çš„åŸºç¡€ç®—æ³•

---

## 3ï¸âƒ£ æ•°å­¦åŸç†

### ç›®æ ‡å‡½æ•°

K-Means çš„ç›®æ ‡æ˜¯æœ€å°åŒ–**ç°‡å†…å¹³æ–¹å’Œ**ï¼ˆWithin-Cluster Sum of Squares, WCSSï¼‰ï¼Œä¹Ÿç§°ä¸º**æƒ¯æ€§**ï¼ˆInertiaï¼‰ï¼š

```math
J = \sum_{i=1}^{K}\sum_{\mathbf{x} \in C_i}||\mathbf{x} - \boldsymbol{\mu}_i||^2
```

å…¶ä¸­ï¼š
- $C_i$ æ˜¯ç¬¬ $i$ ä¸ªç°‡
- $\boldsymbol{\mu}_i$ æ˜¯ç¬¬ $i$ ä¸ªç°‡çš„ä¸­å¿ƒ
- $||\cdot||$ æ˜¯æ¬§å‡ é‡Œå¾—è·ç¦»

### ç®—æ³•æµç¨‹

1. **åˆå§‹åŒ–**ï¼šéšæœºé€‰æ‹© $K$ ä¸ªæ ·æœ¬ä½œä¸ºåˆå§‹èšç±»ä¸­å¿ƒ $\boldsymbol{\mu}_1, \boldsymbol{\mu}_2, ..., \boldsymbol{\mu}_K$

2. **åˆ†é…æ­¥éª¤**ï¼ˆE-Stepï¼‰ï¼šå°†æ¯ä¸ªæ ·æœ¬åˆ†é…åˆ°æœ€è¿‘çš„èšç±»ä¸­å¿ƒ

```math
c^{(i)} = \arg\min_{j}||\mathbf{x}^{(i)} - \boldsymbol{\mu}_j||^2
```

3. **æ›´æ–°æ­¥éª¤**ï¼ˆM-Stepï¼‰ï¼šé‡æ–°è®¡ç®—æ¯ä¸ªç°‡çš„ä¸­å¿ƒ

```math
\boldsymbol{\mu}_j = \frac{1}{|C_j|}\sum_{\mathbf{x} \in C_j}\mathbf{x}
```

4. **æ”¶æ•›åˆ¤æ–­**ï¼šé‡å¤æ­¥éª¤ 2-3ï¼Œç›´åˆ°ä¸­å¿ƒä¸å†å˜åŒ–æˆ–è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°

### æ—¶é—´å¤æ‚åº¦

- å•æ¬¡è¿­ä»£ï¼š$O(NKd)$
  - $N$ï¼šæ ·æœ¬æ•°é‡
  - $K$ï¼šèšç±»æ•°é‡
  - $d$ï¼šç‰¹å¾ç»´åº¦

---

## 4ï¸âƒ£ äº¤äº’å¼å®éªŒ âš¡

è°ƒæ•´èšç±»æ•°é‡ $K$ï¼Œè§‚å¯Ÿå¯¹èšç±»æ•ˆæœçš„å½±å“ï¼š

<KMeansDemo />

---

## 5ï¸âƒ£ ä»£ç å®ç°

### Python å®ç°ï¼ˆscikit-learnï¼‰

```python
from sklearn.cluster import KMeans
from sklearn.datasets import make_blobs
import matplotlib.pyplot as plt

# ç”Ÿæˆç¤ºä¾‹æ•°æ®
X, y_true = make_blobs(n_samples=300, centers=4, cluster_std=0.60, random_state=0)

# åˆ›å»º K-Means æ¨¡å‹
kmeans = KMeans(
    n_clusters=4,           # èšç±»æ•°é‡
    init='k-means++',       # åˆå§‹åŒ–æ–¹æ³•
    max_iter=300,           # æœ€å¤§è¿­ä»£æ¬¡æ•°
    n_init=10,              # è¿è¡Œæ¬¡æ•°ï¼ˆé€‰æ‹©æœ€ä½³ç»“æœï¼‰
    random_state=42
)

# è®­ç»ƒæ¨¡å‹
kmeans.fit(X)

# é¢„æµ‹
labels = kmeans.predict(X)
centers = kmeans.cluster_centers_

# è¯„ä¼°
print(f"æƒ¯æ€§ï¼ˆInertiaï¼‰: {kmeans.inertia_:.2f}")
print(f"è¿­ä»£æ¬¡æ•°: {kmeans.n_iter_}")

# å¯è§†åŒ–
plt.figure(figsize=(10, 6))
plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis', alpha=0.6)
plt.scatter(centers[:, 0], centers[:, 1], c='red', marker='X', s=200, edgecolor='black', label='Centroids')
plt.title('K-Means Clustering')
plt.legend()
plt.show()
```

### ä»é›¶å®ç° K-Means

```python
import numpy as np

def kmeans(X, K, max_iters=100):
    # éšæœºåˆå§‹åŒ–èšç±»ä¸­å¿ƒ
    np.random.seed(42)
    centroids = X[np.random.choice(X.shape[0], K, replace=False)]
    
    for iteration in range(max_iters):
        # E-Step: åˆ†é…æ ·æœ¬åˆ°æœ€è¿‘çš„ä¸­å¿ƒ
        distances = np.sqrt(((X - centroids[:, np.newaxis])**2).sum(axis=2))
        labels = np.argmin(distances, axis=0)
        
        # M-Step: æ›´æ–°èšç±»ä¸­å¿ƒ
        new_centroids = np.array([X[labels == k].mean(axis=0) for k in range(K)])
        
        # æ£€æŸ¥æ”¶æ•›
        if np.allclose(centroids, new_centroids):
            print(f"æ”¶æ•›äºç¬¬ {iteration} æ¬¡è¿­ä»£")
            break
        
        centroids = new_centroids
    
    return labels, centroids

# ä½¿ç”¨
labels, centers = kmeans(X, K=4)
```

---

## 6ï¸âƒ£ é€‰æ‹©æœ€ä¼˜ K å€¼

### è‚˜éƒ¨æ³•åˆ™ï¼ˆElbow Methodï¼‰

ç»˜åˆ¶ä¸åŒ $K$ å€¼ä¸‹çš„æƒ¯æ€§ï¼ˆInertiaï¼‰ï¼Œå¯»æ‰¾"è‚˜éƒ¨"ï¼ˆæ‹ç‚¹ï¼‰ï¼š

```python
inertias = []
K_range = range(1, 11)

for k in K_range:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X)
    inertias.append(kmeans.inertia_)

# ç»˜åˆ¶è‚˜éƒ¨æ›²çº¿
plt.figure(figsize=(10, 6))
plt.plot(K_range, inertias, 'bo-')
plt.xlabel('èšç±»æ•°é‡ K')
plt.ylabel('æƒ¯æ€§ï¼ˆInertiaï¼‰')
plt.title('è‚˜éƒ¨æ³•åˆ™')
plt.grid(True)
plt.show()
```

### è½®å»“ç³»æ•°ï¼ˆSilhouette Scoreï¼‰

è¡¡é‡æ ·æœ¬ä¸å…¶æ‰€åœ¨ç°‡çš„ç›¸ä¼¼åº¦ï¼š

```math
s(i) = \frac{b(i) - a(i)}{\max(a(i), b(i))}
```

å…¶ä¸­ï¼š
- $a(i)$ï¼šæ ·æœ¬ $i$ ä¸åŒç°‡å…¶ä»–æ ·æœ¬çš„å¹³å‡è·ç¦»
- $b(i)$ï¼šæ ·æœ¬ $i$ ä¸æœ€è¿‘å…¶ä»–ç°‡çš„å¹³å‡è·ç¦»

å€¼åŸŸï¼š$[-1, 1]$ï¼Œè¶Šæ¥è¿‘ 1 è¶Šå¥½ã€‚

```python
from sklearn.metrics import silhouette_score

silhouette_scores = []
K_range = range(2, 11)

for k in K_range:
    kmeans = KMeans(n_clusters=k, random_state=42)
    labels = kmeans.fit_predict(X)
    score = silhouette_score(X, labels)
    silhouette_scores.append(score)

# ç»˜åˆ¶è½®å»“ç³»æ•°æ›²çº¿
plt.figure(figsize=(10, 6))
plt.plot(K_range, silhouette_scores, 'go-')
plt.xlabel('èšç±»æ•°é‡ K')
plt.ylabel('è½®å»“ç³»æ•°')
plt.title('è½®å»“ç³»æ•°åˆ†æ')
plt.grid(True)
plt.show()
```

---

## 7ï¸âƒ£ K-Means++ åˆå§‹åŒ–

æ ‡å‡† K-Means å¯¹åˆå§‹ä¸­å¿ƒæ•æ„Ÿï¼Œ**K-Means++** æ”¹è¿›äº†åˆå§‹åŒ–ç­–ç•¥ï¼š

1. éšæœºé€‰æ‹©ç¬¬ä¸€ä¸ªä¸­å¿ƒ $\boldsymbol{\mu}_1$
2. å¯¹äºæ¯ä¸ªæ ·æœ¬ $\mathbf{x}$ï¼Œè®¡ç®—å…¶åˆ°æœ€è¿‘ä¸­å¿ƒçš„è·ç¦» $D(\mathbf{x})$
3. ä»¥æ¦‚ç‡ $\frac{D(\mathbf{x})^2}{\sum_{\mathbf{x}'}D(\mathbf{x}')^2}$ é€‰æ‹©ä¸‹ä¸€ä¸ªä¸­å¿ƒ
4. é‡å¤æ­¥éª¤ 2-3ï¼Œç›´åˆ°é€‰æ‹©äº† $K$ ä¸ªä¸­å¿ƒ

```python
kmeans = KMeans(n_clusters=4, init='k-means++', random_state=42)
```

---

## 8ï¸âƒ£ ä¼˜ç¼ºç‚¹åˆ†æ

### âœ… ä¼˜ç‚¹

- **ç®€å•é«˜æ•ˆ**ï¼šæ˜“äºç†è§£å’Œå®ç°ï¼Œè®¡ç®—é€Ÿåº¦å¿«
- **å¯æ‰©å±•**ï¼šé€‚åˆå¤§è§„æ¨¡æ•°æ®é›†
- **æ”¶æ•›ä¿è¯**ï¼šç®—æ³•ä¿è¯æ”¶æ•›ï¼ˆä½†å¯èƒ½æ˜¯å±€éƒ¨æœ€ä¼˜ï¼‰
- **å¹¿æ³›åº”ç”¨**ï¼šåœ¨å·¥ä¸šç•Œå’Œå­¦æœ¯ç•Œéƒ½éå¸¸æµè¡Œ

### âŒ ç¼ºç‚¹

- **éœ€è¦é¢„è®¾ K å€¼**ï¼šèšç±»æ•°é‡éœ€è¦äº‹å…ˆæŒ‡å®š
- **å¯¹åˆå§‹å€¼æ•æ„Ÿ**ï¼šä¸åŒåˆå§‹ä¸­å¿ƒå¯èƒ½å¯¼è‡´ä¸åŒç»“æœ
- **åªèƒ½å‘ç°å‡¸å½¢ç°‡**ï¼šå¯¹éçƒå½¢ç°‡æ•ˆæœä¸ä½³
- **å¯¹å¼‚å¸¸å€¼æ•æ„Ÿ**ï¼šæç«¯å€¼ä¼šå½±å“èšç±»ä¸­å¿ƒ
- **å‡è®¾ç°‡å¤§å°ç›¸ä¼¼**ï¼šå¯¹å¤§å°å·®å¼‚æ˜¾è‘—çš„ç°‡æ•ˆæœä¸ä½³

---

## 9ï¸âƒ£ å®é™…åº”ç”¨æ¡ˆä¾‹

### æ¡ˆä¾‹1ï¼šå®¢æˆ·ç»†åˆ†

```python
import pandas as pd

# å®¢æˆ·æ•°æ®ï¼šå¹´é¾„ã€æ”¶å…¥ã€æ¶ˆè´¹é‡‘é¢
customers = pd.read_csv('customers.csv')
X = customers[['age', 'income', 'spending']].values

# æ ‡å‡†åŒ–
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# èšç±»
kmeans = KMeans(n_clusters=5, random_state=42)
customers['cluster'] = kmeans.fit_predict(X_scaled)

# åˆ†ææ¯ä¸ªç°‡çš„ç‰¹å¾
print(customers.groupby('cluster').mean())
```

### æ¡ˆä¾‹2ï¼šå›¾åƒå‹ç¼©

```python
from sklearn.cluster import KMeans
from PIL import Image
import numpy as np

# åŠ è½½å›¾åƒ
img = Image.open('photo.jpg')
img_array = np.array(img)
h, w, c = img_array.shape

# å°†å›¾åƒé‡å¡‘ä¸ºäºŒç»´æ•°ç»„
pixels = img_array.reshape(-1, 3)

# K-Means èšç±»ï¼ˆå‡å°‘é¢œè‰²æ•°é‡ï¼‰
kmeans = KMeans(n_clusters=16, random_state=42)
labels = kmeans.fit_predict(pixels)
compressed_pixels = kmeans.cluster_centers_[labels]

# é‡å¡‘å›å›¾åƒå½¢çŠ¶
compressed_img = compressed_pixels.reshape(h, w, c).astype(np.uint8)

# ä¿å­˜å‹ç¼©å›¾åƒ
Image.fromarray(compressed_img).save('compressed.jpg')
```

---

## ğŸ”Ÿ å˜ä½“ç®—æ³•

### Mini-Batch K-Means

ä½¿ç”¨å°æ‰¹é‡æ ·æœ¬æ›´æ–°èšç±»ä¸­å¿ƒï¼Œé€‚åˆè¶…å¤§è§„æ¨¡æ•°æ®ï¼š

```python
from sklearn.cluster import MiniBatchKMeans

mbkmeans = MiniBatchKMeans(
    n_clusters=4,
    batch_size=100,
    random_state=42
)
mbkmeans.fit(X)
```

### K-Medoidsï¼ˆPAMï¼‰

ä½¿ç”¨å®é™…æ ·æœ¬ä½œä¸ºèšç±»ä¸­å¿ƒï¼Œå¯¹å¼‚å¸¸å€¼æ›´é²æ£’ï¼š

```python
from sklearn_extra.cluster import KMedoids

kmedoids = KMedoids(n_clusters=4, random_state=42)
kmedoids.fit(X)
```

---

## ğŸ¯ å…³é”®è¦ç‚¹

1. K-Means é€šè¿‡**è¿­ä»£ä¼˜åŒ–**æœ€å°åŒ–ç°‡å†…å¹³æ–¹å’Œ
2. ç®—æ³•åˆ†ä¸º**åˆ†é…æ­¥éª¤**ï¼ˆE-Stepï¼‰å’Œ**æ›´æ–°æ­¥éª¤**ï¼ˆM-Stepï¼‰
3. éœ€è¦**é¢„è®¾èšç±»æ•°é‡ K**ï¼Œå¯é€šè¿‡è‚˜éƒ¨æ³•åˆ™æˆ–è½®å»“ç³»æ•°é€‰æ‹©
4. **K-Means++** åˆå§‹åŒ–ç­–ç•¥èƒ½æ˜¾è‘—æå‡æ€§èƒ½
5. å¯¹**åˆå§‹å€¼æ•æ„Ÿ**ï¼Œé€šå¸¸è¿è¡Œå¤šæ¬¡é€‰æ‹©æœ€ä½³ç»“æœ
6. é€‚ç”¨äº**å‡¸å½¢ç°‡**ï¼Œå¯¹éçƒå½¢ã€å¤§å°å·®å¼‚å¤§çš„ç°‡æ•ˆæœä¸ä½³
7. **ç®€å•é«˜æ•ˆ**ï¼Œæ˜¯èšç±»åˆ†æçš„é¦–é€‰ç®—æ³•

