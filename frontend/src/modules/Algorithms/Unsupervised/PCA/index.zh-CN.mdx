import { useState } from 'react';
import { useTranslation } from 'react-i18next';
import axios from 'axios';
import { useLogger } from '@common/modules/Logger';
import { useExceptions, ExceptionType, ExceptionSeverity } from '@common/modules/Exceptions';

export const PCADemo = () => {
  const { t } = useTranslation();
  const logger = useLogger();
  const { captureException } = useExceptions();
  const [nComponents, setNComponents] = useState(2);
  const [loading, setLoading] = useState(false);
  const [result, setResult] = useState(null);

  const runPCA = async () => {
    setLoading(true);
    logger.info('开始 PCA 降维', { nComponents });
    
    try {
      const response = await axios.post('/api/algorithms/unsupervised/pca/transform', {
        n_components: nComponents,
      });
      setResult(response.data);
      logger.info('PCA 降维成功', { result: response.data });
    } catch (error) {
      logger.error('PCA 降维失败', { error: error.message, nComponents });
      captureException(error, {
        type: ExceptionType.NETWORK,
        severity: ExceptionSeverity.HIGH,
        context: { 
          algorithm: 'pca',
          nComponents,
          message: 'PCA 降维失败，请检查后端服务是否正常运行'
        }
      });
      setResult({ error: 'PCA 降维失败，请检查控制台获取详细信息' });
    } finally {
      setLoading(false);
    }
  };

  return (
    <div className="demo-container">
      <div className="demo-parameters">
        <h3>PCA 参数</h3>
        <div className="parameter-group">
          <label htmlFor="nComponents">组件数量:</label>
          <input
            id="nComponents"
            type="number"
            value={nComponents}
            onChange={(e) => setNComponents(parseInt(e.target.value))}
            min="1"
            max="10"
          />
        </div>
        <button onClick={runPCA} disabled={loading}>
          {loading ? '转换中...' : '应用 PCA'}
        </button>
      </div>

      {result && (
        <div className="demo-results">
          <h3>PCA 结果</h3>
          <pre>{JSON.stringify(result, null, 2)}</pre>
        </div>
      )}
    </div>
  );
};

# 主成分分析 (PCA)

主成分分析（PCA）是一种降维技术，将数据转换到低维空间，同时尽可能保留方差。它广泛用于数据可视化、噪声减少和特征提取。

## PCA 的工作原理

PCA 通过找到数据变化最大的方向（主成分）来工作。算法遵循以下步骤：

### 1. 数据居中
- 从每个数据点减去均值
- 确保数据以原点为中心

### 2. 协方差矩阵计算
- 计算居中数据的协方差矩阵
- 显示特征如何一起变化

### 3. 特征值分解
- 找到协方差矩阵的特征值和特征向量
- 特征值表示每个成分解释的方差量
- 特征向量表示最大方差的方向

### 4. 成分选择
- 选择前 k 个特征向量（主成分）
- 将数据转换到新的坐标系

## 数学基础

对于具有 n 个样本和 p 个特征的数据集 X：

1. **数据居中**：X_centered = X - μ
2. **计算协方差矩阵**：C = (1/n) * X_centered^T * X_centered
3. **找到特征值和特征向量**：C * v = λ * v
4. **按特征值排序**：λ₁ ≥ λ₂ ≥ ... ≥ λₚ
5. **选择前 k 个成分**：V_k = [v₁, v₂, ..., vₖ]
6. **转换数据**：Y = X_centered * V_k

## 交互式演示

尝试使用不同参数进行 PCA 转换：

<PCADemo />

## 实现示例

以下是使用 Python 和 scikit-learn 的 PCA 实现：

```python
from sklearn.decomposition import PCA
from sklearn.datasets import load_iris
import matplotlib.pyplot as plt

# 加载样本数据
iris = load_iris()
X = iris.data
y = iris.target

# 应用 PCA
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)

# 可视化结果
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis')
plt.xlabel('第一主成分')
plt.ylabel('第二主成分')
plt.title('鸢尾花数据集的 PCA')
plt.show()

# 解释方差比
print(f'解释方差比: {pca.explained_variance_ratio_}')
```

## 关键概念

### 解释方差
- 每个成分解释的总方差百分比
- 有助于确定保留多少个成分
- 所有解释方差比的总和等于 1.0

### 主成分
- 最大方差的正交方向
- 第一个成分捕获最多方差
- 后续成分捕获剩余方差

### 特征值
- 沿每个主成分的方差度量
- 较大的特征值表示更重要的成分

## 应用场景

- **数据可视化**：将高维数据降维到 2D 或 3D 进行绘图
- **噪声减少**：移除低方差成分（通常是噪声）
- **特征提取**：创建捕获重要模式的新特征
- **数据压缩**：在保留信息的同时减少存储需求
- **预处理**：为其他机器学习算法准备数据

## 优势

- **线性变换**：简单且可解释
- **方差保留**：在降维中保持最大方差
- **正交成分**：主成分不相关
- **计算效率**：对大多数数据集计算快速
- **无参数**：无需调优超参数（除了成分数量）

## 局限性

- **线性假设**：假设特征之间存在线性关系
- **基于方差**：可能不保留重要的非方差信息
- **可解释性**：主成分可能没有明确的含义
- **对缩放敏感**：需要特征标准化才能获得有意义的结果
- **信息丢失**：降维总是会丢失一些信息

## 参数选择

### 成分数量
- **方差阈值**：保留解释 95% 方差的成分
- **肘部方法**：在解释方差图中寻找"肘部"
- **交叉验证**：使用下游任务性能选择成分
- **可视化**：使用 2-3 个成分进行可视化

### 数据预处理
- **标准化**：在应用 PCA 之前始终标准化特征
- **缺失值**：在应用 PCA 之前处理缺失值
- **异常值**：考虑移除异常值，因为它们会影响主成分

## 最佳实践

1. **标准化特征**：在应用 PCA 之前使用 StandardScaler
2. **检查方差**：绘制解释方差比以了解数据结构
3. **验证结果**：使用交叉验证确保 PCA 提高性能
4. **解释成分**：尝试理解每个成分代表什么
5. **监控信息丢失**：跟踪丢失了多少方差

## 高级技术

### 核 PCA
- 使用核函数的 PCA 非线性版本
- 可以捕获数据中的非线性关系
- 比线性 PCA 计算更昂贵

### 增量 PCA
- 适用于大型数据集的内存高效版本
- 批量处理数据
- 当数据无法装入内存时有用

### 稀疏 PCA
- 产生稀疏主成分
- 比密集成分更容易解释
- 适用于特征选择

## 与其他方法的比较

### vs 线性判别分析 (LDA)
- **目标**：PCA 最大化方差，LDA 最大化类分离
- **监督**：PCA 是无监督的，LDA 是有监督的
- **成分**：PCA 成分是正交的，LDA 成分不是

### vs t-SNE
- **目的**：PCA 用于线性降维，t-SNE 用于非线性可视化
- **距离**：PCA 保留全局结构，t-SNE 保留局部结构
- **速度**：PCA 更快，t-SNE 更慢

## 可视化

PCA 常用于数据可视化：

```python
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA

# 2D 可视化
pca_2d = PCA(n_components=2)
X_2d = pca_2d.fit_transform(X)
plt.scatter(X_2d[:, 0], X_2d[:, 1], c=y)
plt.show()

# 3D 可视化
pca_3d = PCA(n_components=3)
X_3d = pca_3d.fit_transform(X)
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.scatter(X_3d[:, 0], X_3d[:, 1], X_3d[:, 2], c=y)
plt.show()
```
