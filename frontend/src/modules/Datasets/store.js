import { create } from 'zustand';

/**
 * æ•°æ®é›†æ¨¡å— - çŠ¶æ€ç®¡ç†
 * ä½¿ç”¨ Zustand è¿›è¡Œå…¨å±€æ•°æ®é›†ç®¡ç†ï¼Œæ— éœ€ Provider
 * 
 * ğŸ“‹ æ–‡ä»¶ç»“æ„ï¼š
 * 1. æ•°æ®é›†å…ƒä¿¡æ¯é…ç½® (DATASETS_METADATA)
 * 2. å·¥å…·å‡½æ•° (CSV è§£æã€æ•°æ®å¤„ç†)
 * 3. Zustand Store (useDatasets)
 * 
 * ğŸ’¡ åŠŸèƒ½è¯´æ˜ï¼š
 * - ç®¡ç†å¤šä¸ªæœºå™¨å­¦ä¹ æ•°æ®é›†çš„åŠ è½½å’Œç¼“å­˜
 * - æä¾›ç»Ÿä¸€çš„æ•°æ®è®¿é—®æ¥å£
 * - æ”¯æŒç‰¹å¾å’Œæ ‡ç­¾çš„è‡ªåŠ¨æå–
 */

// ============================================
// æ•°æ®é›†å…ƒä¿¡æ¯é…ç½®
// ============================================

/**
 * æ•°æ®é›†å…ƒä¿¡æ¯
 * åŒ…å«æ‰€æœ‰å¯ç”¨æ•°æ®é›†çš„é…ç½®ä¿¡æ¯
 */
export const DATASETS_METADATA = {
  // é¸¢å°¾èŠ±æ•°æ®é›† - ç»å…¸å¤šåˆ†ç±»é—®é¢˜
  iris: {
    name: 'Iris Dataset',
    nameZh: 'é¸¢å°¾èŠ±æ•°æ®é›†',
    description: 'Classic dataset for multi-class classification',
    descriptionZh: 'ç»å…¸çš„å¤šåˆ†ç±»æ•°æ®é›†',
    samples: 150,
    features: 4,
    classes: 3,
    targetColumn: 'target',
    featureColumns: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'],
    classNames: ['setosa', 'versicolor', 'virginica'],
    type: 'classification',
    path: '/aiml-studio/datasets/iris.csv'
  },
  
  // åŠ å·æˆ¿ä»·æ•°æ®é›† - å›å½’é—®é¢˜
  california_housing: {
    name: 'California Housing',
    nameZh: 'åŠ å·æˆ¿ä»·æ•°æ®é›†',
    description: 'Regression dataset for house price prediction',
    descriptionZh: 'ç”¨äºæˆ¿ä»·é¢„æµ‹çš„å›å½’æ•°æ®é›†',
    samples: 20640,
    features: 8,
    targetColumn: 'MedHouseVal',
    featureColumns: ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude'],
    type: 'regression',
    path: '/aiml-studio/datasets/california_housing.csv'
  },
  
  // çº¢é…’æ•°æ®é›† - å¤šåˆ†ç±»é—®é¢˜
  wine: {
    name: 'Wine Dataset',
    nameZh: 'çº¢é…’æ•°æ®é›†',
    description: 'Chemical analysis of wines',
    descriptionZh: 'çº¢é…’çš„åŒ–å­¦åˆ†ææ•°æ®',
    samples: 178,
    features: 13,
    classes: 3,
    targetColumn: 'target',
    type: 'classification',
    path: '/aiml-studio/datasets/wine.csv'
  },
  
  // ä¹³è…ºç™Œæ•°æ®é›† - äºŒåˆ†ç±»é—®é¢˜
  breast_cancer: {
    name: 'Breast Cancer',
    nameZh: 'ä¹³è…ºç™Œæ•°æ®é›†',
    description: 'Binary classification for cancer diagnosis',
    descriptionZh: 'ç”¨äºç™Œç—‡è¯Šæ–­çš„äºŒåˆ†ç±»æ•°æ®é›†',
    samples: 569,
    features: 30,
    classes: 2,
    targetColumn: 'target',
    classNames: ['malignant', 'benign'],
    type: 'classification',
    path: '/aiml-studio/datasets/breast_cancer.csv'
  },
  
  // æ‰‹å†™æ•°å­—æ•°æ®é›† - å¤šåˆ†ç±»é—®é¢˜
  digits: {
    name: 'Digits Dataset',
    nameZh: 'æ‰‹å†™æ•°å­—æ•°æ®é›†',
    description: '8x8 images of handwritten digits',
    descriptionZh: '8x8 åƒç´ çš„æ‰‹å†™æ•°å­—å›¾åƒ',
    samples: 1797,
    features: 64,
    classes: 10,
    targetColumn: 'target',
    type: 'classification',
    path: '/aiml-studio/datasets/digits.csv'
  },
  
  // ç³–å°¿ç—…æ•°æ®é›† - å›å½’é—®é¢˜
  diabetes: {
    name: 'Diabetes Dataset',
    nameZh: 'ç³–å°¿ç—…æ•°æ®é›†',
    description: 'Diabetes disease progression prediction',
    descriptionZh: 'ç³–å°¿ç—…ç—…ç¨‹é¢„æµ‹æ•°æ®é›†',
    samples: 442,
    features: 10,
    targetColumn: 'target',
    type: 'regression',
    path: '/aiml-studio/datasets/diabetes.csv'
  }
};

// ============================================
// å·¥å…·å‡½æ•°
// ============================================

/**
 * è§£æ CSV æ–‡æœ¬
 * @param {string} csvText - CSV æ–‡æœ¬å†…å®¹
 * @returns {Object} { headers: string[], data: Object[] }
 */
function parseCSV(csvText) {
  const lines = csvText.trim().split('\n');
  const headers = lines[0].split(',').map(h => h.trim());
  
  const data = lines.slice(1).map(line => {
    const values = line.split(',');
    const row = {};
    
    headers.forEach((header, index) => {
      const value = values[index]?.trim();
      // å°è¯•è½¬æ¢ä¸ºæ•°å­—
      row[header] = isNaN(value) ? value : parseFloat(value);
    });
    
    return row;
  });
  
  return { headers, data };
}

// ============================================
// Zustand Store
// ============================================

/**
 * Datasets Store
 * æä¾›å…¨å±€æ•°æ®é›†ç®¡ç†åŠŸèƒ½
 */
export const useDatasets = create((set, get) => ({
  // ============================================
  // çŠ¶æ€
  // ============================================
  
  /** æ•°æ®é›†ç¼“å­˜ */
  datasets: {},
  
  /** åŠ è½½çŠ¶æ€ */
  loading: {},
  
  /** é”™è¯¯ä¿¡æ¯ */
  errors: {},

  /** æ•°æ®é›†å…ƒä¿¡æ¯ï¼ˆæ–¹ä¾¿è®¿é—®ï¼‰ */
  metadata: DATASETS_METADATA,

  // ============================================
  // æ ¸å¿ƒæ•°æ®åŠ è½½æ–¹æ³•
  // ============================================

  /**
   * åŠ è½½æ•°æ®é›†
   * @param {string} datasetName - æ•°æ®é›†åç§°
   * @returns {Promise<Object>} åŠ è½½çš„æ•°æ®é›†å¯¹è±¡
   */
  loadDataset: async (datasetName) => {
    const { datasets } = get();
    
    // å¦‚æœå·²ç»åŠ è½½è¿‡ï¼Œç›´æ¥è¿”å›
    if (datasets[datasetName]) {
      return datasets[datasetName];
    }
    
    // æ£€æŸ¥æ•°æ®é›†æ˜¯å¦å­˜åœ¨
    if (!DATASETS_METADATA[datasetName]) {
      const error = `Dataset "${datasetName}" not found`;
      set(state => ({
        errors: { ...state.errors, [datasetName]: error }
      }));
      throw new Error(error);
    }
    
    // è®¾ç½®åŠ è½½çŠ¶æ€
    set(state => ({
      loading: { ...state.loading, [datasetName]: true },
      errors: { ...state.errors, [datasetName]: null }
    }));
    
    try {
      const path = DATASETS_METADATA[datasetName].path;
      const response = await fetch(path);
      
      if (!response.ok) {
        throw new Error(`Failed to load dataset: ${response.statusText}`);
      }
      
      const csvText = await response.text();
      const { headers, data } = parseCSV(csvText);
      
      const dataset = {
        name: datasetName,
        metadata: DATASETS_METADATA[datasetName],
        headers,
        data,
        shape: [data.length, headers.length]
      };
      
      // ç¼“å­˜æ•°æ®é›†
      set(state => ({
        datasets: { ...state.datasets, [datasetName]: dataset },
        loading: { ...state.loading, [datasetName]: false }
      }));
      
      return dataset;
    } catch (error) {
      set(state => ({
        loading: { ...state.loading, [datasetName]: false },
        errors: { ...state.errors, [datasetName]: error.message }
      }));
      throw error;
    }
  },

  // ============================================
  // æ•°æ®å¤„ç†æ–¹æ³•
  // ============================================

  /**
   * è·å–æ•°æ®é›†çš„ç‰¹å¾å’Œæ ‡ç­¾
   * @param {string} datasetName - æ•°æ®é›†åç§°
   * @returns {Object} { X: number[][], y: number[], featureColumns: string[] }
   * @throws {Error} å¦‚æœæ•°æ®é›†æœªåŠ è½½
   */
  getFeatureAndTarget: (datasetName) => {
    const { datasets } = get();
    const dataset = datasets[datasetName];
    
    if (!dataset) {
      throw new Error(`Dataset "${datasetName}" not loaded`);
    }
    
    const meta = DATASETS_METADATA[datasetName];
    const targetColumn = meta.targetColumn;
    const featureColumns = meta.featureColumns || 
      dataset.headers.filter(h => h !== targetColumn);
    
    // æå–ç‰¹å¾çŸ©é˜µ X
    const X = dataset.data.map(row => 
      featureColumns.map(col => row[col])
    );
    
    // æå–æ ‡ç­¾å‘é‡ y
    const y = dataset.data.map(row => row[targetColumn]);
    
    return { X, y, featureColumns };
  },

  /**
   * è·å–æ‰€æœ‰å¯ç”¨çš„æ•°æ®é›†åˆ—è¡¨
   * @returns {Object} æ•°æ®é›†å…ƒä¿¡æ¯å¯¹è±¡
   */
  getAvailableDatasets: () => {
    return DATASETS_METADATA;
  },

  // ============================================
  // ç¼“å­˜ç®¡ç†æ–¹æ³•
  // ============================================

  /**
   * æ¸…é™¤æŒ‡å®šæ•°æ®é›†çš„ç¼“å­˜
   * @param {string} datasetName - æ•°æ®é›†åç§°
   */
  clearDataset: (datasetName) => {
    set(state => {
      const newDatasets = { ...state.datasets };
      delete newDatasets[datasetName];
      return { datasets: newDatasets };
    });
  },

  /**
   * æ¸…é™¤æ‰€æœ‰ç¼“å­˜
   */
  clearAll: () => {
    set({
      datasets: {},
      loading: {},
      errors: {}
    });
  },
}));
